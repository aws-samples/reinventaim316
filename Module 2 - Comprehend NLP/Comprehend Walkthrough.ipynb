{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <b> Comprehend Primitives and Pre-Built API's </b></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Amazon Comprehend is a natural-language processing (NLP) service that uses machine learning to uncover valuable insights and connections in text. We will explore 6 pre-trained APIs: Identifying Named Entities, Extracting Key Phrases, Identifying the Dominant Language, Determining Emotional sentiment, Determining Syntax, Detecting Detect Personally Identifiable Information (PII)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intialize the comprehend client with Boto3\n",
    "comprehend = boto3.client(service_name='comprehend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample text we will be using with Comprehend\n",
    "sample_text = '''\n",
    "Hello Zhang Wei. Your AnyCompany Financial Services, LLC credit card account 1111-0000-1111-0000 has a minimum payment of $24.53 that is due by July 31st. Based on your autopay settings, we will withdraw your payment on the due date from your bank account XXXXXX1111 with the routing number XXXXX0000. \n",
    "Your latest statement was mailed to 100 Main Street, Anytown, WA 98121. \n",
    "After your payment is received, you will receive a confirmation text message at 206-555-0100. \n",
    "If you have questions about your bill, AnyCompany Customer Service is available by phone at 206-555-0199 or email at support@anycompany.com.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Identifying Named Entities</h1>\n",
    "\n",
    "A named entity is a real-world object (persons, places, locations, organizations, etc.) that can be denoted with a proper name. Amazon Comprehend can extract named entities from a document or text. This can be useful, for example, for indexing, document labeling or search. For more information, see Detect Entities). The API used to extract these entities is the DetectEntities API. For each entity detected Amazon Comprehend returns both the type, for instance \"Person\" or \"Date\", as well as a confidence score which indicates how confident the model is in this detection. In your implementation you can use this confidence score to set threshold values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect and print entities\n",
    "detected_entities = comprehend.detect_entities(Text=sample_text, LanguageCode='en')\n",
    "pprint.pprint(detected_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the entity detection ouput, you will see 5 elements. BeginOffset and EndOffset are the place in the document the text in relation to characters. Ex. Zhang Wei starts at character 7 and finishes at character 16. Score is the confidence of the predicition, text is the text that was classified and type is the entity that was detected.This response pattern is common across nearly all Amazon Comprehend API commands.You can build <b>Custom Entity Detection </b> and we will touch on this in a later workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying values in a more huamn readable way\n",
    "detectec_entities_df = pd.DataFrame([ [entity['Text'], entity['Type'], entity['Score']] for entity in detected_entities['Entities']],\n",
    "                columns=['Text', 'Type', 'Score'])\n",
    "display (detectec_entities_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Detecting Key Phrases</h1>\n",
    "\n",
    "Amazon Comprehend can extract key noun phrases that appear in a document. For example, a document about a basketball game might return the names of the teams, the name of the venue, and the final score. This can be used, for example, for indexing or summarization. For more information, see Detect Key Phrases.\n",
    "\n",
    "The API used to extract these key phrases is the DetectKeyPhrases API.\n",
    "\n",
    "Amazon Comprehend returns the key phrases, as well as a confidence score which indicates how confident the model is in this detection. In your implementation you can use this confidence score to set threshold values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call detect key phrases API\n",
    "detected_key_phrases = comprehend.detect_key_phrases(Text=sample_text, LanguageCode='en')\n",
    "pprint.pprint(detected_key_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#displaying values in a more huamn readable way\n",
    "detected_key_phrases_df = pd.DataFrame([ [entity['Text'], entity['Score']] for entity in detected_key_phrases['KeyPhrases']],\n",
    "                columns=['Text', 'Score'])\n",
    "display(detected_key_phrases_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Identifying the Dominant Language</h1>\n",
    "\n",
    "Amazon Comprehend identifies the dominant language in a document. Amazon Comprehend can currently identify many languages. This can be useful as a first step before further processing, for example when phone call transcripts can be in different languages. For more information, including which languages can be identified, see Detect the Dominant Language.\n",
    "\n",
    "The API used to identify the dominant language is the DetectDominantLanguage API.\n",
    "\n",
    "Amazon Comprehend returns the dominant language, as well as a confidence score which indicates how confident the model is in this detection. In your implementation you can use this confidence score to set threshold values. If more than one language is detected, it will return each detected language and its corresponding confidence score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the detect lanaguage \n",
    "detected_language = comprehend.detect_dominant_language(Text=sample_text)\n",
    "pprint.pprint(detected_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making it more human readable\n",
    "detected_language_df = pd.DataFrame([ [code['LanguageCode'], code['Score']] for code in detected_language['Languages']],\n",
    "                columns=['Language Code', 'Score'])\n",
    "display (detected_language_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Determining Emotional Sentiment</h1>\n",
    "\n",
    "Amazon Comprehend determines the emotional sentiment of a document. Sentiment can be positive, neutral, negative, or mixed. For more information, see Determine Sentiment. This can be useful for example to analyze the content of reviews or transcripts from call centres. For more information, see Detecting Sentiment.\n",
    "\n",
    "The API used to extract the emotional sentiment is the DetectSentiment API.\n",
    "\n",
    "Amazon Comprehend returns the different sentiments and the related confidence score for each of them, which indicates how confident the model is in this detection. The sentiment with the highest confidence score can be seen as the predominant sentiment in the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling detect_sentiment \n",
    "detected_sentiment = comprehend.detect_sentiment(Text=sample_text, LanguageCode='en')\n",
    "pprint.pprint(detected_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding predmoninant sentiment and making it more human readable\n",
    "predominant_sentiment = detected_sentiment['Sentiment']\n",
    "detected_sentiments_df = pd.DataFrame([ [sentiment, detected_sentiment['SentimentScore'][sentiment]] for sentiment in detected_sentiment['SentimentScore']],\n",
    "                columns=['Language Code', 'Score'])\n",
    "#Sentiment across Document\n",
    "display(detected_sentiments_df)\n",
    "#Predominant Senitment\n",
    "display(predominant_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1>Detecting Personally Identifiable Information (PII)</h1>\n",
    "\n",
    "Amazon Comprehend analyzes documents to detect personal data that could be used to identify an individual, such as an address, bank account number, or phone number. This can be usefull, for example, for information extraction and indexing, and to comply with legal requirements around data protection. For more information, see Detect Personally Identifiable Information (PII).\n",
    "\n",
    "Amazon Comprehend can help you identify the location of individual PII in your document or help you label documents that contain PII.\n",
    "Identify the location of PII in your text documents\n",
    "\n",
    "Amazon Comprehend can help you identify the location of individual PII in your document. Select \"Offsets\" in the Personally identifiable information (PII) analysis mode.\n",
    "\n",
    "The API used to identify the location of individual PII is the DetectPiiEntities API.\n",
    "\n",
    "Amazon Comprehend returns the different PII and the related confidence score for each of them, which indicates how confident the model is in this detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the Detect PII API\n",
    "detected_pii_entities = comprehend.detect_pii_entities(Text=sample_text, LanguageCode='en')\n",
    "pprint.pprint(detected_pii_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make more human readable\n",
    "detected_pii_entities_df = pd.DataFrame([ [entity['Type'], entity['Score']] for entity in detected_pii_entities['Entities']],\n",
    "                columns=['Type', 'Score'])\n",
    "display (detected_pii_entities_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2>Label text documents with PII</h2>\n",
    "\n",
    "Amazon Comprehend can help you label documents that contain PII. Select \"Labels\" in the Personally identifiable information (PII) analysis mode.\n",
    "\n",
    "The API used to extract the PII enties in the document. We used the ContainsPiiEntities API.\n",
    "\n",
    "Amazon Comprehend returns the different PII labels and the related confidence score for each of them, which indicates how confident the model is in this detection. These labels indicate the presence of these types of PII in the document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelelling Text in a Document\n",
    "detected_pii_labels = comprehend.contains_pii_entities(Text=sample_text, LanguageCode='en')\n",
    "pprint.pprint(detected_pii_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make more human readable\n",
    "detected_pii_labels_df = pd.DataFrame([ [entity['Name'], entity['Score']] for entity in detected_pii_labels['Labels']],\n",
    "                columns=['Name', 'Score'])\n",
    "display (detected_pii_labels_df)\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
